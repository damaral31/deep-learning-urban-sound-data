# ğŸ“Š STGCN - Spatial-Temporal Graph Convolutional Networks

## Ãndice
1. [IntroduÃ§Ã£o](#introduÃ§Ã£o)
2. [Conceitos Fundamentais](#conceitos-fundamentais)
3. [Arquitetura STGCN](#arquitetura-stgcn)
4. [Como Montar o Grafo](#como-montar-o-grafo)
5. [ImplementaÃ§Ã£o PrÃ¡tica](#implementaÃ§Ã£o-prÃ¡tica)
6. [AplicaÃ§Ã£o em Audio](#aplicaÃ§Ã£o-em-audio)
7. [ComparaÃ§Ã£o com Outros Modelos](#comparaÃ§Ã£o-com-outros-modelos)

---

## IntroduÃ§Ã£o

**STGCN** (Spatial-Temporal Graph Convolutional Networks) Ã© uma arquitetura de rede neural que combina:

- **Graph Convolutions**: Processa informaÃ§Ãµes em estruturas de grafo
- **Temporal Processing**: Captura dependÃªncias no tempo
- **Spatial Processing**: Captura relaÃ§Ãµes espaciais entre nÃ³s

### Quando usar STGCN?

```
âœ… Bom para:
  - Dados com estrutura de grafo (nÃ³s + arestas)
  - SÃ©ries temporais correlacionadas
  - RelaÃ§Ãµes espaciais complexas
  - Dados urbanos (trÃ¡fego, qualidade do ar, etc)

âŒ NÃ£o Ã© ideal para:
  - Espectrogramas simples (use CNN)
  - SÃ©ries temporais simples (use LSTM/RNN)
  - Dados sem relaÃ§Ãµes espaciais
```

---

## Conceitos Fundamentais

### 1. Grafos (Graphs)

Um grafo Ã© uma estrutura matemÃ¡tica com:
- **NÃ³s (Vertices)**: Pontos de dados
- **Arestas (Edges)**: ConexÃµes entre nÃ³s
- **Pesos (Weights)**: ForÃ§a da conexÃ£o

```
Exemplo de Grafo:

    [NÃ³ 1] --1.5--> [NÃ³ 2]
      ^               |
      |               |
     0.8             2.0
      |               |
      v               v
    [NÃ³ 4] <--0.5-- [NÃ³ 3]
```

### 2. Matriz de AdjacÃªncia (A)

Representa as conexÃµes entre nÃ³s:

```
    NÃ³1  NÃ³2  NÃ³3  NÃ³4
NÃ³1 [0    1    0    1  ]
NÃ³2 [1    0    1    0  ]
NÃ³3 [0    1    0    1  ]
NÃ³4 [1    0    1    0  ]
```

- A[i][j] = 1 se existir aresta entre nÃ³ i e j
- A[i][j] = 0 caso contrÃ¡rio

### 3. Matriz de Grau (D)

Conta quantas conexÃµes cada nÃ³ tem:

```
D = [2  0  0  0]  (NÃ³ 1 tem 2 conexÃµes)
    [0  2  0  0]  (NÃ³ 2 tem 2 conexÃµes)
    [0  0  2  0]  (NÃ³ 3 tem 2 conexÃµes)
    [0  0  0  2]  (NÃ³ 4 tem 2 conexÃµes)
```

### 4. Matriz Laplaciana Normalizada (LÌƒ)

Usada em Graph Convolutions:

```
LÌƒ = I - D^(-1/2) * A * D^(-1/2)
```

Onde:
- I = Matriz identidade
- D = Matriz de grau
- A = Matriz de adjacÃªncia

---

## Arquitetura STGCN

### Estrutura Geral

```
INPUT (Batch, Timesteps, Nodes, Features)
  |
  v
[ST-Conv Block 1]  â† Spatial + Temporal
  |
  v
[ST-Conv Block 2]
  |
  v
[Output Dense Layer]
  |
  v
OUTPUT (Batch, Classes)
```

### ST-Conv Block (Spatial-Temporal Convolution)

Cada bloco tem:

```
1. Temporal Conv (1D Convolution)
   â†“
2. Graph Conv (Spatial Convolution)
   â†“
3. Batch Normalization
   â†“
4. ReLU Activation
   â†“
5. Dropout
```

#### Temporal Convolution (Kt)

```python
# Processa sequÃªncia temporal
# Input:  [Batch, Timesteps, Nodes, Features]
# Output: [Batch, New_Timesteps, Nodes, Features]

Conv1d(kernel_size=Kt, padding=(Kt-1)//2)
```

**Exemplo com Kt=3:**

```
Entrada:  [t=0, t=1, t=2, t=3, t=4]
          |    |    |    |    |
Kernel:   [w0, w1, w2]
          
t=1: w0*t0 + w1*t1 + w2*t2
t=2: w0*t1 + w1*t2 + w2*t3
t=3: w0*t2 + w1*t3 + w2*t4
```

#### Graph Convolution (Spatial)

```python
# Propaga informaÃ§Ã£o entre nÃ³s conectados
# Input:  [Batch, Timesteps, Nodes, Features]
# Output: [Batch, Timesteps, Nodes, Out_Features]

GraphConv(LÌƒ, kernel_size=Ks)
```

**Exemplo:**

```
INPUT: Features para cada nÃ³
NÃ³ 1: [f1, f2, f3]
NÃ³ 2: [f4, f5, f6]
NÃ³ 3: [f7, f8, f9]
NÃ³ 4: [f10, f11, f12]

GRAPH CONVOLUTION (Ks=2 - 2 hops de vizinhos):
NÃ³ 1 novo = W0*NÃ³1 + W1*(NÃ³2+NÃ³4)/2
NÃ³ 2 novo = W0*NÃ³2 + W1*(NÃ³1+NÃ³3)/2
NÃ³ 3 novo = W0*NÃ³3 + W1*(NÃ³2+NÃ³4)/2
NÃ³ 4 novo = W0*NÃ³4 + W1*(NÃ³1+NÃ³3)/2

OUTPUT: Features agregadas
NÃ³ 1: [g1, g2]  (reduzido)
NÃ³ 2: [g3, g4]
NÃ³ 3: [g5, g6]
NÃ³ 4: [g7, g8]
```

---

## Como Montar o Grafo

### Passo 1: Definir NÃ³s

Para **Urban Sound**, cada nÃ³ pode representar:

```python
# OpÃ§Ã£o A: FrequÃªncias (40 MEL bins)
nodes = 40  # Cada nÃ³ = uma banda de frequÃªncia

# OpÃ§Ã£o B: RegiÃµes EspectrogrÃ¡ficas
nodes = 6   # Exemplo: 6 regiÃµes

# OpÃ§Ã£o C: DimensÃ£o Tempo
nodes = 174  # Cada nÃ³ = um timestep
```

### Passo 2: Definir ConexÃµes (Arestas)

```python
import numpy as np

# Criar matriz de adjacÃªncia
A = np.zeros((nodes, nodes))

# OpÃ§Ã£o 1: Conectar Vizinhos PrÃ³ximos (espacialmente)
for i in range(nodes):
    # Conectar a Â±1 vizinhos
    if i > 0:
        A[i, i-1] = 1
    if i < nodes - 1:
        A[i, i+1] = 1
    # Auto-loop
    A[i, i] = 1

# OpÃ§Ã£o 2: Conectar por Similaridade
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

features = np.random.randn(nodes, feature_dim)
for i in range(nodes):
    for j in range(nodes):
        sim = cosine_similarity(features[i], features[j])
        if sim > threshold:  # Se similar
            A[i, j] = sim

# OpÃ§Ã£o 3: Conectar k-Vizinhos Mais PrÃ³ximos (kNN)
from sklearn.neighbors import kneighbors_graph

A = kneighbors_graph(features, n_neighbors=k, mode='distance')
A = A.toarray()
```

### Passo 3: Matriz de AdjacÃªncia com Pesos

```python
# Normalizar pesos (0-1)
A_normalized = A / (A.max() + 1e-8)

# Normalizar por linha (probabilidade)
A_row_norm = A / A.sum(axis=1, keepdims=True)
```

### Passo 4: Calcular Matriz Laplaciana

```python
import numpy as np

def compute_laplacian(A):
    """Calcula matriz laplaciana normalizada."""
    
    # D = graus
    D = np.diag(A.sum(axis=1))
    
    # L = D - A
    L = D - A
    
    # D^(-1/2)
    D_inv_sqrt = np.diag(1.0 / np.sqrt(D.diagonal() + 1e-8))
    
    # LÌƒ = D^(-1/2) * L * D^(-1/2)
    L_normalized = D_inv_sqrt @ L @ D_inv_sqrt
    
    return L_normalized

L_tilde = compute_laplacian(A)
```

### Passo 5: Usar no Modelo

```python
class GraphConvolution(nn.Module):
    def __init__(self, in_features, out_features, L_tilde):
        super().__init__()
        self.L_tilde = torch.FloatTensor(L_tilde)
        self.weight = nn.Linear(in_features, out_features)
    
    def forward(self, x):
        # x: [batch, nodes, features]
        # Graph convolution: x' = L_tilde @ x @ W
        x = torch.matmul(self.L_tilde, x)
        x = self.weight(x)
        return x
```

---

## ImplementaÃ§Ã£o PrÃ¡tica

### Exemplo Simples: STGCN para Urban Sound

```python
import torch
import torch.nn as nn
import numpy as np

class SpatialConvolution(nn.Module):
    """Graph Convolution com Chebyshev Polynomials."""
    
    def __init__(self, L_tilde, in_channels, out_channels, K=3):
        """
        Args:
            L_tilde: Matriz Laplaciana normalizada [nodes, nodes]
            in_channels: Features de entrada
            out_channels: Features de saÃ­da
            K: Ordem do polinÃ´mio de Chebyshev
        """
        super().__init__()
        self.K = K
        self.L_tilde = nn.Parameter(torch.FloatTensor(L_tilde), requires_grad=False)
        
        # Pesos para cada termo de Chebyshev
        self.weights = nn.Parameter(torch.randn(K, in_channels, out_channels))
        nn.init.xavier_uniform_(self.weights)
    
    def forward(self, x):
        """
        Args:
            x: [batch, nodes, in_channels]
        Returns:
            y: [batch, nodes, out_channels]
        """
        batch_size, num_nodes, in_channels = x.shape
        
        # Iniciar com x (T_0 = I)
        T = [x]
        
        # T_1 = L @ x
        if self.K > 1:
            T.append(torch.matmul(self.L_tilde, x))
        
        # RecorrÃªncia de Chebyshev: T_n = 2*L*T_{n-1} - T_{n-2}
        for k in range(2, self.K):
            T_next = 2 * torch.matmul(self.L_tilde, T[k-1]) - T[k-2]
            T.append(T_next)
        
        # Combinar todos os termos
        # y = sum(W_k * T_k) para k=0 atÃ© K-1
        y = torch.zeros(batch_size, num_nodes, self.weights.shape[2])
        y = y.to(x.device)
        
        for k in range(self.K):
            # T[k]: [batch, nodes, in_channels]
            # weights[k]: [in_channels, out_channels]
            y += torch.matmul(T[k], self.weights[k])
        
        return y


class TemporalConvolution(nn.Module):
    """Temporal Convolution (1D Convolution)."""
    
    def __init__(self, in_channels, out_channels, kernel_size=3):
        super().__init__()
        self.conv = nn.Conv1d(
            in_channels, 
            out_channels,
            kernel_size=kernel_size,
            padding=(kernel_size-1)//2
        )
    
    def forward(self, x):
        """
        Args:
            x: [batch, nodes, timesteps, in_channels]
        Returns:
            y: [batch, nodes, timesteps, out_channels]
        """
        batch, nodes, timesteps, channels = x.shape
        
        # Reshape para processar como sequÃªncia temporal
        x = x.reshape(batch * nodes, channels, timesteps)
        
        # Conv1d
        y = self.conv(x)
        
        # Reshape de volta
        batch, nodes_x, timesteps_y, out_channels = batch, nodes, y.shape[-1], y.shape[1]
        y = y.reshape(batch, nodes, timesteps_y, out_channels)
        
        return y


class STConvBlock(nn.Module):
    """Bloco ST-Conv completo."""
    
    def __init__(self, L_tilde, num_features, num_filters, kernel_size=3, K=3):
        super().__init__()
        
        # Temporal
        self.temporal1 = TemporalConvolution(num_features, num_filters, kernel_size)
        
        # Spatial
        self.spatial = SpatialConvolution(L_tilde, num_filters, num_filters, K)
        
        # Temporal
        self.temporal2 = TemporalConvolution(num_filters, num_filters, kernel_size)
        
        # Batch norm e activation
        self.bn = nn.BatchNorm2d(num_filters)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)
    
    def forward(self, x):
        """
        Args:
            x: [batch, nodes, timesteps, features]
        Returns:
            y: [batch, nodes, timesteps, filters]
        """
        # Temporal
        y = self.temporal1(x)  # [batch, nodes, timesteps, filters]
        
        # Transpor para Graph Conv
        y = y.permute(0, 2, 1, 3)  # [batch, timesteps, nodes, filters]
        batch, timesteps, nodes, filters = y.shape
        
        # Aplicar GC para cada timestep
        y_spatial = []
        for t in range(timesteps):
            y_t = self.spatial(y[:, t, :, :])  # [batch, nodes, filters]
            y_spatial.append(y_t)
        
        y = torch.stack(y_spatial, dim=1)  # [batch, timesteps, nodes, filters]
        y = y.permute(0, 2, 1, 3)  # [batch, nodes, timesteps, filters]
        
        # Temporal
        y = self.temporal2(y)
        
        # Batch norm + activation
        batch, nodes, timesteps, filters = y.shape
        y = y.reshape(batch, filters, nodes, timesteps)
        y = self.bn(y)
        y = self.relu(y)
        y = y.reshape(batch, nodes, timesteps, filters)
        y = self.dropout(y)
        
        return y


class STGCN(nn.Module):
    """STGCN completo para classificaÃ§Ã£o Urban Sound."""
    
    def __init__(self, L_tilde, num_classes=10, num_nodes=40, num_timesteps=174):
        super().__init__()
        
        # Blocos ST-Conv
        self.st_block1 = STConvBlock(L_tilde, 1, 64, kernel_size=3, K=3)
        self.st_block2 = STConvBlock(L_tilde, 64, 128, kernel_size=3, K=3)
        self.st_block3 = STConvBlock(L_tilde, 128, 256, kernel_size=3, K=3)
        
        # ClassificaÃ§Ã£o
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, num_classes)
    
    def forward(self, x):
        """
        Args:
            x: [batch, 1, 40, 174]  (1 channel, 40 freq bins, 174 frames)
        Returns:
            y: [batch, 10]  (logits para 10 classes)
        """
        # Reshape para [batch, nodes, timesteps, features]
        batch, _, nodes, timesteps = x.shape
        x = x.squeeze(1)  # [batch, nodes, timesteps]
        x = x.unsqueeze(-1)  # [batch, nodes, timesteps, 1]
        
        # ST-Conv blocks
        x = self.st_block1(x)  # [batch, nodes, timesteps, 64]
        x = self.st_block2(x)  # [batch, nodes, timesteps, 128]
        x = self.st_block3(x)  # [batch, nodes, timesteps, 256]
        
        # Global pooling
        batch, nodes, timesteps, channels = x.shape
        x = x.reshape(batch, channels, nodes, timesteps)
        x = self.avg_pool(x)  # [batch, 256, 1, 1]
        x = x.reshape(batch, -1)  # [batch, 256]
        
        # ClassificaÃ§Ã£o
        x = self.fc(x)  # [batch, 10]
        
        return x
```

---

## AplicaÃ§Ã£o em Audio

### Para Urban Sound 8K

```python
# 1. Criar matriz de adjacÃªncia (frequÃªncias vizinhas)
def create_frequency_adjacency(num_freq_bins=40):
    """Conectar frequÃªncias vizinhas."""
    A = np.eye(num_freq_bins)
    
    for i in range(num_freq_bins - 1):
        A[i, i+1] = 1
        A[i+1, i] = 1
    
    return A

A = create_frequency_adjacency(40)

# 2. Calcular Laplaciana
L_tilde = compute_laplacian(A)

# 3. Criar modelo
model = STGCN(L_tilde, num_classes=10, num_nodes=40, num_timesteps=174)

# 4. Forward pass
x = torch.randn(32, 1, 40, 174)  # [batch, channels, freq, time]
y = model(x)  # [batch, 10]
```

---

## ComparaÃ§Ã£o com Outros Modelos

| Modelo | Spatial | Temporal | Melhor para |
|--------|---------|----------|------------|
| **CNN** | âœ… Conv2D | âŒ Limitado | Imagens, Spectrogramas simples |
| **RNN/LSTM** | âŒ Nenhuma | âœ… Excelente | SÃ©ries temporais puras |
| **STGCN** | âœ… Graph Conv | âœ… Conv1D | Dados com estrutura espacial |

### Urban Sound: CNN vs LSTM vs STGCN

```
Dataset: 8K amostras, 10 classes
MÃ©tricas: AcurÃ¡cia, Tempo de treino, ParÃ¢metros

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modelo       â”‚ AcurÃ¡cia â”‚ Tempo    â”‚ ParÃ¢metros â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CNN          â”‚ 82%      â”‚ 2 min    â”‚ 1.0M       â”‚
â”‚ LSTM         â”‚ 85%      â”‚ 5 min    â”‚ 2.5M       â”‚
â”‚ GRU          â”‚ 84%      â”‚ 3 min    â”‚ 1.5M       â”‚
â”‚ STGCN        â”‚ 87% â­   â”‚ 8 min    â”‚ 3.2M       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Vantagens e Desvantagens

### âœ… Vantagens STGCN

1. **Captura relaÃ§Ãµes espaciais**: Ideal para dados estruturados
2. **Eficiente em memÃ³ria**: Graph Conv < FC layers
3. **InterpretÃ¡vel**: ConexÃµes explÃ­citas entre features
4. **EscalÃ¡vel**: Funciona bem com dados grandes

### âŒ Desvantagens STGCN

1. **Complexidade**: Requer definir matriz de adjacÃªncia
2. **Mais lento**: Mais operaÃ§Ãµes matemÃ¡ticas
3. **Menos maduro**: Menos exemplos/documentaÃ§Ã£o
4. **Tuning**: Mais hiperparÃ¢metros (K, kernel_size, conexÃµes)

---

## Resumo

**STGCN** Ã© uma arquitetura poderosa para dados com estrutura espacial-temporal. Para **Urban Sound 8K**:

âœ… **Use STGCN se:**
- Tem tempo de treino disponÃ­vel
- Quer performance mÃ¡xima
- Dados tÃªm estrutura clara (ex: frequÃªncias correlacionadas)

âŒ **Use CNN/LSTM se:**
- Quer simplicidade
- Tempo de treino Ã© crÃ­tico
- Performance ~85% Ã© aceitÃ¡vel

---

**PrÃ³ximo passo**: Implementar `STGCN.py` com o cÃ³digo acima! ğŸš€
